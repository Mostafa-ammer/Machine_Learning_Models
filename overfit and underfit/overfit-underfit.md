# what is overfitting ?

Overfitting is a common problem in machine learning and statistical modeling where a model learns the training data too well, to the point that it captures noise, random fluctuations, and outliers in the data rather than the underlying patterns and relationships. In other words, an overfit model fits the training data so closely that it fails to generalize well to new, unseen data.

![Alt text](https://th.bing.com/th/id/OIP.6dU52VqZASz0G9MWs3dXIQAAAA?pid=ImgDet&rs=1)

# what are the Key characteristics of overfitting ?
1- High Variance
2- Complexity
3- Sensitive to Noise
4- Poor Generalization
5- Perfect Fit to Training Data

# what are various techniques can be applied to address overfitting  ?

1- Regularization: Adding regularization terms to the model's objective function (e.g., L1 or L2 regularization) to penalize overly complex models.
2- Increasing Training Data: Gathering more training data, if possible, to provide the model with a larger and more diverse dataset
3- Feature Selection: Carefully selecting relevant features and removing irrelevant or noisy ones.
4- Simplifying Model Complexity: Reducing the model's capacity by using simpler architectures or fewer parameters.
5- Cross-Validation: Using cross-validation to evaluate model performance on validation data and select the best model.

